#!/usr/bin/env yue
--- SPDX-License-Identifier: 0BSD

from _G import type, error, assert, print, tostring, ipairs, io, os, debug, table, string

import "lpegrex"


macro log = (...) ->
	const argc = select("#", ...)
	const argv = { ... }

	local code = ""

	for i = 1, argc
		const expr = argv[i]
		const expr_quoted = "%q"::format(expr)
		code ..= "(function(x)
	local type_of_x = type(x)
	if type_of_x == \"string\" then
		x = (\"%q\"):format(x)
	else
		x = tostring(x)
	end
	print((\"%s: %s = %s\"):format(#{expr_quoted}, type_of_x, x))
end)(#{expr});"

	{
		type: "lua",
		:code,
	}


export check_arguments = (func_name, arguments) ->
	for arg in *arguments
		const [index, name, expected_type, value] = arg

		const type_of_value = type(value)

		if type_of_value == expected_type
			continue

		error("Wrong type of argument #%d %q to function %q! (expected %s, got: %s)"::format(
			index,
			name,
			func_name,
			expected_type,
			type_of_value,
		))


export grammar = do
	const script_path = ($FILE) -- debug.getinfo(1, "S").source
	assert(type(script_path) == "string")

	local script_dir, path_delimiter, script_file = script_path::match("^(.+)([/\\])([^/\\]+)$")

	script_dir     ??= "."
	path_delimiter ??= "/"
	script_file    ??= ($FILE)

	--$log(script_path, script_dir, path_delimiter, script_file)

	const grammar_file_path = script_dir .. path_delimiter .. "grammar.lpegrex"
	close file = assert(io.open(grammar_file_path, mode))

	file::read("*a")


export class Token
	new: (@name, @pos, @endpos, @value) =>
		check_arguments("Token.__init", [
			[1, "self",   "table",  @],
			[2, "name",   "string", name],
			[3, "pos",    "number", pos],
			[4, "endpos", "number", endpos],
			[5, "value",  "string", value],
		])

	--- This method uses another (currently private) library of mine to convert
	--- objects into strings with ANSI colors for pretty-printing to the
	--- terminal. You need to provide your own implementation if you want to
	--- make use of it.
	__pretty: () =>
		check_arguments("Token.__init", [
			[1, "self", "table", @],
		])
		import "pretty"

		"\027[1;36m#{@@__name}\027[22;39m(" .. table.concat([
			pretty(@name),
			pretty(@pos),
			pretty(@endpos),
			pretty(@value),
		], "\027[35m,\027[39m ") .. ")"

	__repr: () =>
		check_arguments("Token.__init", [
			[1, "self", "table", @],
		])

		"%s(%q, %d, %d, %q)"::format(
			@@__name,
			@name,
			@pos,
			@endpos,
			@value,
		)

	__tostring: () =>
		check_arguments("Token.__init", [
			[1, "self", "table", @],
		])

		@value

	__concat: (other) =>
		check_arguments("Token.__init", [
			[1, "self", "table", @],
		])

		@value .. tostring(other)


export tokenizer = lpegrex.compile(grammar, {
	__options: {
		tag: (tag, node) -> Token(tag, node.pos, node.endpos, node[1])
	}
})


export tokenize = (source_code, file_name="<unknown>") ->
	check_arguments("tokenize", [
		[1, "source_code", "string", source_code],
		[2, "file_name",   "string", file_name],
	])

	const tokens, error_label, error_position = tokenizer::match(source_code)

	const type_of_tokens = type(tokens)
	if type_of_tokens == "table"
		return tokens

	if (error_label == nil) or (error_position == nil)
		error("The tokenizer returned an incorrect type! (expected %q, got: %q)"::format(
			"table",
			type_of_tokens,
		))

	const line_number, column_number, line = lpegrex.calcline(source_code, error_position)

	const column_indicator = " "::rep(column_number - 1) .. "\027[1;31m^\027[0m"

	error("Syntax error at %s:%d:%d -> %s\n%s\n%s"::format(
		file_name,
		line_number,
		column_number,
		error_label,
		line,
		column_indicator,
	))


export try_tokenize = (source_code, file_name="<unknown>") ->
	error("TODO")


export visualize = (tokens) ->
	io.write("\027[30m\n")
	for i, token in ipairs(tokens)
		io.write(
			"\027[4%dm"::format((i - 1) % 6 + 1),
			tostring(token)
		)
	io.write("\027[0m\n")
	io.flush()


export main = (argv=arg) ->
	--const test_code = if file_path := argv[1]
	--	close file = io.open(file_path, "r")
	--	file::read("*a")
	--else
	--	[===[if true then print("Yes") else print('No', 0x10)]===]
	const test_code = [===[if true then print("Yes", [[At least, I think]]) else print('No', 0x10)]===]

	$log(test_code)
	print()

	const tokens = tokenize(test_code)

	for token in *tokens
		print(token::__repr())

	visualize(tokens)


if select("#", ...) == 0
	os.exit(main())
